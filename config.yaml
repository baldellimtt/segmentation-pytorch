# Configuration file for segmentation model training

# CONFIGURAZIONE AUGMENTATION (Albumentations)
#
# Puoi specificare la pipeline di augmentation come una lista ordinata di trasformazioni.
# Ogni trasformazione è un dizionario con almeno il campo 'name' (nome della transform di albumentations) e i relativi parametri.
#
# - Tutte le transform vengono applicate in sequenza (come Compose implicito).
# - Puoi usare 'OneOf' per scegliere randomicamente UNA sola tra più transform (vedi esempio sotto).
# - Puoi usare 'Compose' per raggruppare alcune transform in sequenza (annidamento), ma la pipeline principale è già una Compose.
#
# Esempio:
#
# augmentation:
#   - name: HorizontalFlip
#     p: 0.5
#   - name: OneOf
#     transforms:
#       - name: RandomBrightnessContrast
#         p: 0.6
#       - name: RandomGamma
#         p: 0.4
#     p: 0.8
#   - name: Blur
#     p: 0.2
#   - name: Compose
#     transforms:
#       - name: GridDropout
#         p: 0.2
#         ratio: 0.3
#         unit_size_range: [10, 20]
#         fill: random_uniform
#       - name: RandomFog
#         p: 0.2
#         alpha: 0.03
#     p: 1.0
#
# - 'OneOf': applica una sola delle transform elencate (random, secondo p)
# - 'Compose': applica tutte le transform elencate in sequenza (utile per raggruppare)
#
# Puoi aggiungere qualsiasi transform di albumentations seguendo questa sintassi.

model:
  input_size: [512, 512]  # Image resize dimensions (height, width)
  architecture: fpn
  backbone: resnet34
  in_channels: 3
  out_classes: 1

seed: 42

training:
  epochs: 550
  batch_size: 1
  lr: 0.001  # Learning rate
  num_workers: 2  # Number of workers for data loading

augmentation:
  - name: HorizontalFlip
    p: 0.9
  - name: GaussNoise
    p: 0.3
  - name: OneOf
    transforms:
      - name: RandomBrightnessContrast
        p: 0.6
      - name: RandomGamma
        p: 0.4
    p: 0.8
  - name: Blur
    p: 0.5
  - name: Affine
    rotate: [-5, 5]
    scale: [0.95, 1.05]
    translate_percent:
      x: [-0.03, 0.03]
      y: [-0.03, 0.03]
    p: 0.2
  - name: GridDropout
    p: 0.2
    ratio: 0.3
    unit_size_range: [10, 20]
    fill: random_uniform
  - name: RandomFog
    p: 0.2
    alpha: 0.03

# Data paths and configuration
data:
  splits_dir:  ../segmentation-pytorch/dataset_creation  # Directory containing train.txt, val.txt, test.txt
  images_dir: ../images  # Update with your images path
  masks_dir: ../masks    # Update with your masks path

# Dataset split configuration
split_ratios:
  train: 0.7   # 70% for training
  val: 0.15    # 15% for validation
  test: 0.15   # 15% for testing

output:
  checkpoint_dir: C:/Users/Andrea/Desktop/segmentation-pytorch/checkpoints
  checkpoint_name: best_model
  monitor: valid_loss
  save_top_k: 1
  mode: min

inference:
  model_path: ../checkpoints/best_model-v3.ckpt
  input_images_dir: ../images_test
  outputs_dir: ../output_images

# Miscellaneous
show_augmentation_samples: true 